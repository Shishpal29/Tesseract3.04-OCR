{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir number_plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!export root_dir=pwd\n",
    "!echo \"$root_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"./number_plate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/shishpal/BARC/Tesseract-OCR/Tesseract/number_plate'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#                         Training Tesseract 3.04\n",
    "- Tesseract is an optical character recognition engine for various operating systems.\n",
    "- Tesseract 3.x is based on traditional computer vision algorithms.\n",
    "- Version 4 of Tesseract also has the legacy OCR engine of Tesseract 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Requirements for text input files\n",
    "Text input files need to meet these criteria:\n",
    "- ASCII or UTF-8 encoding without BOM\n",
    "- Unix end-of-line marker ('\\n')\n",
    "- The last character must be an end of line marker ('\\n')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Code for Generating text file\n",
    "\n",
    "- Run below python code to generate training_text.txt file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indian number plate general format generator\n",
    "import random\n",
    "import string\n",
    "random.seed(0)\n",
    "state_code = ['AP','AR','AS','BR','CG','GA','GJ','HR','HP','JK','JH','KA','KL',\n",
    "\t      'MP','MH','MN','ML','MZ','NL','OD','PB','RJ','SK','TN','TS','TR','UK',\n",
    "\t      'UP','WB','AN','CH','DN','DD','DL','LD','PY']\n",
    "punc=['-','.',' ']\n",
    "def randomStringL(stringLength):\n",
    "    return ''.join(random.choice(state_code))\n",
    "def randomStringL2(stringLength):\n",
    "    letters = string.uppercase\n",
    "    return ''.join(random.choice(letters) for i in range(2))\n",
    "def randomStringD(stringLength):\n",
    "    letters = string.digits\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))\n",
    "def randomBet():\n",
    "    return ''.join(random.choice(punc))\n",
    "output= ''\n",
    "for i in range(1000):\n",
    "  rnd = randomBet()\n",
    "  output = output + (randomStringL(2)+rnd+randomStringD(2)+rnd+randomStringL2(2)+rnd+randomStringD(4) )+'\\n'\n",
    "\n",
    "file = open(\"training_text.txt\",\"w\")\n",
    "file.write(output)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Procedure\n",
    "\n",
    "### 1. Generate Training Images and Box Files\n",
    "##### 1.1 Automated Method\n",
    "- Run the following command for each font in turn to create a matching tif/box file pair. \n",
    "- input:  UTF-8 text file (training_text.txt) containing our training text.\n",
    " ```sh\n",
    " $ text2image --text=training_text.txt --outputbase=[lang].[fontname].exp0 --font='Font Name' --fonts_dir=/path/to/our/fonts\n",
    " ```\n",
    " - copy fonts from \"/usr/share/fonts\" directory to our data directory or set path accordingly.\n",
    "- Three files (eng.FreeSerifBold.exp0.box, eng.FreeSerifBold.exp0.tif, lang.unicharset) created in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendered page 0 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 1 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 2 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 3 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 4 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 5 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 6 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 7 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 8 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 9 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 10 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 11 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 12 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 13 to file eng.FreeSerifBold.exp0.tif\n",
      "Rendered page 14 to file eng.FreeSerifBold.exp0.tif\n"
     ]
    }
   ],
   "source": [
    "!text2image --text=training_text.txt --outputbase=eng.FreeSerifBold.exp0 --font='FreeSerif Bold' --fonts_dir=../data/fonts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run Tesseract for Training\n",
    "For each of our training image, boxfile pairs, run Tesseract in training mode:\n",
    "```sh\n",
    "$ tesseract [lang].[fontname].exp[num].tif [lang].[fontname].exp[num] box.train\n",
    "```\n",
    "- The output of this step is tr file which contains the features of each character of the training page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
      "Page 1\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     804\n",
      "   Found 804 good blobs.\n",
      "Generated training data for 164 words\n",
      "Page 2\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     810\n",
      "   Found 810 good blobs.\n",
      "Generated training data for 165 words\n",
      "Page 3\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     825\n",
      "   Found 825 good blobs.\n",
      "Generated training data for 145 words\n",
      "Page 4\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     816\n",
      "   Found 816 good blobs.\n",
      "Generated training data for 150 words\n",
      "Page 5\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     822\n",
      "   Found 822 good blobs.\n",
      "Generated training data for 146 words\n",
      "Page 6\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     825\n",
      "   Found 825 good blobs.\n",
      "Generated training data for 144 words\n",
      "Page 7\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     840\n",
      "   Found 840 good blobs.\n",
      "Generated training data for 132 words\n",
      "Page 8\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     819\n",
      "   Found 819 good blobs.\n",
      "Generated training data for 153 words\n",
      "Page 9\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     828\n",
      "   Found 828 good blobs.\n",
      "Generated training data for 147 words\n",
      "Page 10\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     825\n",
      "   Found 825 good blobs.\n",
      "Generated training data for 142 words\n",
      "Page 11\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     825\n",
      "   Found 825 good blobs.\n",
      "Generated training data for 141 words\n",
      "Page 12\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     825\n",
      "   Found 825 good blobs.\n",
      "Generated training data for 145 words\n",
      "Page 13\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     846\n",
      "   Found 846 good blobs.\n",
      "Generated training data for 121 words\n",
      "Page 14\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     840\n",
      "   Found 840 good blobs.\n",
      "Generated training data for 127 words\n",
      "Page 15\n",
      "APPLY_BOXES:\n",
      "   Boxes read from boxfile:     415\n",
      "   Found 415 good blobs.\n",
      "Generated training data for 65 words\n"
     ]
    }
   ],
   "source": [
    "!tesseract eng.FreeSerifBold.exp0.tif eng.FreeSerifBold.exp0 box.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate the unicharset file\n",
    "- Tesseract’s unicharset file contains information on each symbol the Tesseract OCR engine is trained to recognize.\n",
    "- Currently, generating the unicharset file is done in two steps using these commands: unicharset_extractor and set_unicharset_properties.\n",
    "\n",
    "##### 3.1 unicharset_extractor\n",
    "Tesseract needs to know the set of possible characters it can output. To generate the unicharset data file, use the unicharset_extractor program on the box files generated above:\n",
    "```sh\n",
    "$ unicharset_extractor lang.fontname.exp0.box\n",
    "```\n",
    "- unicharset file will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting unicharset from box file eng.FreeSerifBold.exp0.box\r\n",
      "Other case u of U is not in unicharset\r\n",
      "Other case p of P is not in unicharset\r\n",
      "Other case n of N is not in unicharset\r\n",
      "Other case k of K is not in unicharset\r\n",
      "Other case l of L is not in unicharset\r\n",
      "Other case q of Q is not in unicharset\r\n",
      "Other case g of G is not in unicharset\r\n",
      "Other case m of M is not in unicharset\r\n",
      "Other case c of C is not in unicharset\r\n",
      "Other case d of D is not in unicharset\r\n",
      "Other case o of O is not in unicharset\r\n",
      "Other case a of A is not in unicharset\r\n",
      "Other case z of Z is not in unicharset\r\n",
      "Other case i of I is not in unicharset\r\n",
      "Other case w of W is not in unicharset\r\n",
      "Other case y of Y is not in unicharset\r\n",
      "Other case j of J is not in unicharset\r\n",
      "Other case s of S is not in unicharset\r\n",
      "Other case h of H is not in unicharset\r\n",
      "Other case b of B is not in unicharset\r\n",
      "Other case x of X is not in unicharset\r\n",
      "Other case f of F is not in unicharset\r\n",
      "Other case t of T is not in unicharset\r\n",
      "Other case r of R is not in unicharset\r\n",
      "Other case v of V is not in unicharset\r\n",
      "Other case e of E is not in unicharset\r\n",
      "Wrote unicharset file unicharset\r\n"
     ]
    }
   ],
   "source": [
    "!unicharset_extractor eng.FreeSerifBold.exp0.box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 set_unicharset_properties\n",
    "- This step allow the addition of extra properties in the unicharset.\n",
    "```sh\n",
    "$ set_unicharset_properties -U input_unicharset -O output_unicharset --script_dir=langdata\n",
    "```\n",
    "- output_unicharset file will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded unicharset of size 41 from file unicharset\r\n",
      "Setting unichar properties\r\n",
      "Other case u of U is not in unicharset\r\n",
      "Other case p of P is not in unicharset\r\n",
      "Other case n of N is not in unicharset\r\n",
      "Other case k of K is not in unicharset\r\n",
      "Other case l of L is not in unicharset\r\n",
      "Other case q of Q is not in unicharset\r\n",
      "Other case g of G is not in unicharset\r\n",
      "Other case m of M is not in unicharset\r\n",
      "Other case c of C is not in unicharset\r\n",
      "Other case d of D is not in unicharset\r\n",
      "Other case o of O is not in unicharset\r\n",
      "Other case a of A is not in unicharset\r\n",
      "Other case z of Z is not in unicharset\r\n",
      "Other case i of I is not in unicharset\r\n",
      "Other case w of W is not in unicharset\r\n",
      "Other case y of Y is not in unicharset\r\n",
      "Other case j of J is not in unicharset\r\n",
      "Other case s of S is not in unicharset\r\n",
      "Other case h of H is not in unicharset\r\n",
      "Other case b of B is not in unicharset\r\n",
      "Other case x of X is not in unicharset\r\n",
      "Other case f of F is not in unicharset\r\n",
      "Other case t of T is not in unicharset\r\n",
      "Other case r of R is not in unicharset\r\n",
      "Other case v of V is not in unicharset\r\n",
      "Other case e of E is not in unicharset\r\n",
      "Setting script properties\r\n",
      "Failed to load script unicharset from:../data/langdata/Latin.unicharset\r\n",
      "Warning: properties incomplete for index 3 = U\r\n",
      "Warning: properties incomplete for index 4 = P\r\n",
      "Warning: properties incomplete for index 7 = N\r\n",
      "Warning: properties incomplete for index 8 = K\r\n",
      "Warning: properties incomplete for index 12 = L\r\n",
      "Warning: properties incomplete for index 13 = Q\r\n",
      "Warning: properties incomplete for index 14 = G\r\n",
      "Warning: properties incomplete for index 19 = M\r\n",
      "Warning: properties incomplete for index 20 = C\r\n",
      "Warning: properties incomplete for index 21 = D\r\n",
      "Warning: properties incomplete for index 23 = O\r\n",
      "Warning: properties incomplete for index 24 = A\r\n",
      "Warning: properties incomplete for index 25 = Z\r\n",
      "Warning: properties incomplete for index 26 = I\r\n",
      "Warning: properties incomplete for index 27 = W\r\n",
      "Warning: properties incomplete for index 30 = Y\r\n",
      "Warning: properties incomplete for index 31 = J\r\n",
      "Warning: properties incomplete for index 32 = S\r\n",
      "Warning: properties incomplete for index 33 = H\r\n",
      "Warning: properties incomplete for index 34 = B\r\n",
      "Warning: properties incomplete for index 35 = X\r\n",
      "Warning: properties incomplete for index 36 = F\r\n",
      "Warning: properties incomplete for index 37 = T\r\n",
      "Warning: properties incomplete for index 38 = R\r\n",
      "Warning: properties incomplete for index 39 = V\r\n",
      "Warning: properties incomplete for index 40 = E\r\n",
      "Writing unicharset to file output_unicharset\r\n"
     ]
    }
   ],
   "source": [
    "!set_unicharset_properties --script_dir=../data/langdata -U unicharset -O output_unicharset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For futher details regarding Unicharset — Incomplete properties [click here](https://github.com/tesseract-ocr/tesseract/issues/318)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The font_properties file\n",
    "- Create a font_properties text file. The purpose of this file is to provide font style information that will appear in the output when the font is recognized.\n",
    "- Each line of the font_properties file is formatted as follows: fontname italic bold fixed serif fraktur\n",
    "- Use default [font_properties](https://raw.githubusercontent.com/tesseract-ocr/langdata/master/font_properties) file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Clustering\n",
    "- When the character features of all the training pages have been extracted, we need to cluster them to create the prototypes.\n",
    "- The character shape features can be clustered using the shapeclustering, mftraining and cntraining programs:\n",
    "##### 5.1mftraining\n",
    "- mftraining will output two other data files: inttemp (the shape prototypes) and pffmtable (the number of expected features for each character).\n",
    "- mftraining will produce a shapetable file because we didn't run shapeclustering.\n",
    "```sh\n",
    "$ mftraining -F font_properties -U unicharset -O lang.unicharset lang.fontname.exp0.tr\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No shape table file present: shapetable\n",
      "Reading eng.FreeSerifBold.exp0.tr ...\n",
      "Flat shape table summary: Number of shapes = 38 max unichars = 1 number with multiple unichars = 0\n",
      "Warning: no protos/configs for Joined in CreateIntTemplates()\n",
      "Warning: no protos/configs for |Broken|0|1 in CreateIntTemplates()\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!mftraining -F ../data/font_properties -U unicharset -O eng.unicharset eng.FreeSerifBold.exp0.tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 cntraining\n",
    "- This will output the normproto data file (the character normalization sensitivity prototypes).\n",
    "```sh \n",
    "$ cntraining lang.fontname.exp0.tr\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading eng.FreeSerifBold.exp0.tr ...\n",
      "Clustering ...\n",
      "\n",
      "Writing normproto ...\n"
     ]
    }
   ],
   "source": [
    "!cntraining eng.FreeSerifBold.exp0.tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv inttemp eng.inttemp\n",
    "!mv pffmtable eng.pffmtable\n",
    "!mv shapetable eng.shapetable\n",
    "!rm eng.unicharset\n",
    "!mv output_unicharset eng.unicharset\n",
    "!mv normproto eng.normproto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Putting it all together\n",
    "- now collect together all the files (shapetable, normproto, inttemp, pffmtable, unicharset) and rename them with a lang. prefix (for example eng.) \n",
    "- run combine_tessdata on them as follows:\n",
    "```sh\n",
    "$ combine_tessdata lang.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining tessdata files\r\n",
      "Output eng.traineddata created successfully.\r\n",
      "Version string:4.0.0-beta.1\r\n",
      "1:unicharset:size=2776, offset=192\r\n",
      "3:inttemp:size=517039, offset=2968\r\n",
      "4:pffmtable:size=306, offset=520007\r\n",
      "5:normproto:size=4742, offset=520313\r\n",
      "13:shapetable:size=688, offset=525055\r\n",
      "23:version:size=12, offset=525743\r\n"
     ]
    }
   ],
   "source": [
    "!combine_tessdata eng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../Trained_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv eng.traineddata ../Trained_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shishpal/BARC/Tesseract-OCR/Tesseract\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!rm -rf number_plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The resulting eng.traineddata goes in our Trained_Data directory. \n",
    "- Tesseract can now recognize text in our language (in theory) with the following:\n",
    "```sh\n",
    "$ tesseract image.tif output -l lang\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TESSDATA_PREFIX'] = \"./Trained_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\r\n"
     ]
    }
   ],
   "source": [
    "!tesseract images/image4.png output/output_0 -l eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
      "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
      "Estimating resolution as 1236\n"
     ]
    }
   ],
   "source": [
    "!tesseract images/image3.1.png output/output_1 -l eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\r\n"
     ]
    }
   ],
   "source": [
    "!tesseract images/image-4.png output/output_2 -l eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
